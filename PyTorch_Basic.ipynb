{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch with Jupyter Notebook\n",
    "- 구글 코랩을 쓰는게 나을지 이게 나을지\n",
    "    - 코랩은 어지간한 패키지 내장된 듯. code에서는 venv 내에서 pip 써야 함\n",
    "- md 부분은 md 확장이 먹는 것 같다 더 낫구만.\n",
    "    - 이걸로 갑시다.\n",
    "- 드디어 나도 주피터 노트북 사용자!\n",
    "\n",
    "## 기초공사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본 준비물들\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from varname import nameof\n",
    "\n",
    "def print_info(tensor:torch.FloatTensor):\n",
    "    try:\n",
    "        name_of_var = nameof(tensor)\n",
    "    except:\n",
    "        name_of_var = 'tensor'\n",
    "    print(f'Rank(dim) of {name_of_var} is {tensor.dim()}')\n",
    "    print(f'Size of {name_of_var} is {tensor.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 텐서 조작 기초"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 2. 3. 4. 5. 6.]\n"
     ]
    }
   ],
   "source": [
    "t1 = np.array([0., 1., 2., 3., 4., 5., 6.])\n",
    "print(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank(ndim) of t1 is 1\n",
      "shape of t1 is (7,)\n"
     ]
    }
   ],
   "source": [
    "print(f'rank(ndim) of t1 is {t1.ndim}')\n",
    "print(f'shape of t1 is {t1.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "shape에서 `(7,)`는 `(1,7)`과 같다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  2.  3.]\n",
      " [ 4.  5.  6.]\n",
      " [ 7.  8.  9.]\n",
      " [10. 11. 12.]]\n"
     ]
    }
   ],
   "source": [
    "t2 = np.array([[1., 2., 3.], [4., 5., 6.], [7., 8., 9.], [10., 11., 12.]])\n",
    "print(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank(ndim) of t2 is 2\n",
      "shape of t2 is (4, 3)\n"
     ]
    }
   ],
   "source": [
    "print(f'rank(ndim) of t2 is {t2.ndim}')\n",
    "print(f'shape of t2 is {t2.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch를 한번 써보자\n",
    "- 일단은 `FloatTensor`를 주로 쓸 듯\n",
    "- `dim()`과 `shape`가 있고, `shape`는 `size()`와 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 2., 3., 4., 5., 6.])\n",
      "Rank(dim) of tensor is 1\n",
      "Size of tensor is torch.Size([7])\n",
      "<class 'torch.Size'>\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "pt1 = torch.FloatTensor([0., 1., 2., 3., 4., 5., 6.])\n",
    "print(pt1)\n",
    "print_info(pt1)\n",
    "print(type(pt1.shape))\n",
    "print(pt1.shape == pt1.size())\n",
    "print(pt1.shape is pt1.size()) # 다른 인스턴스이므로 False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.],\n",
      "        [ 7.,  8.,  9.],\n",
      "        [10., 11., 12.]])\n",
      "Rank(dim) of tensor is 2\n",
      "Size of tensor is torch.Size([4, 3])\n"
     ]
    }
   ],
   "source": [
    "pt2 = torch.FloatTensor([[1., 2., 3.],\n",
    "                       [4., 5., 6.],\n",
    "                       [7., 8., 9.],\n",
    "                       [10., 11., 12.]\n",
    "                      ])\n",
    "print(pt2)\n",
    "print_info(pt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 2.,  5.,  8., 11.])\n",
      "tensor(5.)\n",
      "tensor([[ 4.,  5.],\n",
      "        [ 7.,  8.],\n",
      "        [10., 11.]])\n"
     ]
    }
   ],
   "source": [
    "print(pt2[:, 1])\n",
    "print(pt2[1, 1])\n",
    "print(pt2[1:, :-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Broadcasting\n",
    "- 행렬을 더하거나 뺄 때는 크기가 같아야 함.\n",
    "- 곱셈을 할 때는 A의 마지막 차원과 B의 첫번째 차원의 크기가 같아야 함\n",
    "    - 2차원의 경우, A의 열과 B의 행 크기가 같아야 함\n",
    "- 브로드캐스팅은 자동으로 크기를 맞춰서 연산을 수행\n",
    "- **자동으로 이루어지므로 사용에 주의해야 함.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5., 5.]])\n"
     ]
    }
   ],
   "source": [
    "m1 = torch.FloatTensor([[3, 3]])\n",
    "m2 = torch.FloatTensor([[2, 2]])\n",
    "print(m1 + m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4., 5.]])\n",
      "tensor([[3., 6.]])\n"
     ]
    }
   ],
   "source": [
    "# Vector + scalar\n",
    "m1 = torch.FloatTensor([[1, 2]])\n",
    "m2 = torch.FloatTensor([3]) # [3] -> [3, 3]\n",
    "print(m1 + m2)\n",
    "print(m1 * m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4., 5.],\n",
      "        [5., 6.]])\n",
      "tensor([[3., 6.],\n",
      "        [4., 8.]])\n"
     ]
    }
   ],
   "source": [
    "# 2 x 1 Vector + 1 x 2 Vector\n",
    "m1 = torch.FloatTensor([[1, 2]])\n",
    "m2 = torch.FloatTensor([[3], [4]])\n",
    "print(m1 + m2)\n",
    "print(m1 * m2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 위의 경우 브로드캐스팅 과정에서 행렬이 채워짐\n",
    "```\n",
    "[1, 2]\n",
    "==> [[1, 2],\n",
    "     [1, 2]]\n",
    "[3]\n",
    "[4]\n",
    "==> [[3, 3],\n",
    "     [4, 4]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 행렬 곱셈의 차이\n",
    "- 행렬 곱셈은 .matmul, 원소 별 곱셈은 .mul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank(dim) of tensor is 2\n",
      "Size of tensor is torch.Size([2, 2])\n",
      "Rank(dim) of tensor is 2\n",
      "Size of tensor is torch.Size([2, 1])\n",
      "tensor([[ 5.],\n",
      "        [11.]])\n",
      "Rank(dim) of tensor is 2\n",
      "Size of tensor is torch.Size([2, 1])\n"
     ]
    }
   ],
   "source": [
    "m1 = torch.FloatTensor([[1, 2], [3, 4]])\n",
    "m2 = torch.FloatTensor([[1], [2]])\n",
    "print_info(m1)\n",
    "print_info(m2)\n",
    "print(m1.matmul(m2)) # 2 x 1\n",
    "print_info(m1.matmul(m2)) # 2 x 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [6., 8.]])\n",
      "tensor([[1., 2.],\n",
      "        [6., 8.]])\n"
     ]
    }
   ],
   "source": [
    "print(m1 * m2)\n",
    "print(m1.mul(m2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 총합, 평균, 최대값, 최대값 인덱스\n",
    "- sum, mean, man, argmax\n",
    "- 함수에서 dim 인자를 통해 행 혹은 열을 선택할 수 있음\n",
    "    - 2차원의 경우, dim = 0이면 행을 합쳐버리는 것이고, dim = 1이면 열을 합쳐벼리는 것."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "tensor(2.5000)\n"
     ]
    }
   ],
   "source": [
    "t = torch.FloatTensor([[1, 2], [3, 4]])\n",
    "print(t)\n",
    "print(t.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4., 6.])\n",
      "tensor([2., 3.])\n"
     ]
    }
   ],
   "source": [
    "print(t.sum(dim = 0))\n",
    "print(t.mean(dim = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 7.])\n",
      "tensor([1.5000, 3.5000])\n"
     ]
    }
   ],
   "source": [
    "print(t.sum(dim = 1))\n",
    "print(t.mean(dim = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.)\n",
      "tensor(3)\n"
     ]
    }
   ],
   "source": [
    "print(t.max())\n",
    "print(t.argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 5.],\n",
      "        [2., 3.]])\n",
      "tensor([2., 5.])\n",
      "tensor([1, 0])\n"
     ]
    }
   ],
   "source": [
    "t = torch.FloatTensor([[1, 5], [2, 3]])\n",
    "\n",
    "print(t)\n",
    "print(t.max(dim = 0)[0])\n",
    "print(t.argmax(dim = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5., 3.])\n",
      "tensor([1, 1])\n"
     ]
    }
   ],
   "source": [
    "print(t.max(dim = 1)[0])\n",
    "print(t.argmax(dim = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 텐서 조작 추가\n",
    "\n",
    "### 뷰 (중요!?)\n",
    "- 원소의 수를 유지하면서 텐서의 크기를 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.,  1.,  2.],\n",
      "         [ 3.,  4.,  5.]],\n",
      "\n",
      "        [[ 6.,  7.,  8.],\n",
      "         [ 9., 10., 11.]]])\n",
      "Rank(dim) of tensor is 3\n",
      "Size of tensor is torch.Size([2, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "t = np.array([[[0, 1, 2],\n",
    "               [3, 4, 5]],\n",
    "              [[6, 7, 8],\n",
    "               [9, 10, 11]]])\n",
    "ft = torch.FloatTensor(t)\n",
    "print(ft)\n",
    "print_info(ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  1.,  2.],\n",
      "        [ 3.,  4.,  5.],\n",
      "        [ 6.,  7.,  8.],\n",
      "        [ 9., 10., 11.]])\n",
      "Rank(dim) of tensor is 2\n",
      "Size of tensor is torch.Size([4, 3])\n"
     ]
    }
   ],
   "source": [
    "print(ft.view([-1, 3])) # ft라는 텐서를 (?, 3)의 크기로 변경\n",
    "print_info(ft.view([-1, 3]))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "27acd57041ab43bd7420ea3701530ac139f1b2fc5b72b7f2b8dcb4a7eb4acbfb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('venv-mac': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
