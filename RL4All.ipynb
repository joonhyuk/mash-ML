{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모두를 위한 RL 강좌\n",
    "- pygame을 쓴다!?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.0 False {'prob': 0.3333333333333333}\n",
      "2 0.0 False {'prob': 0.3333333333333333}\n",
      "1 0.0 False {'prob': 0.3333333333333333}\n",
      "1 0.0 False {'prob': 0.3333333333333333}\n",
      "0 0.0 False {'prob': 0.3333333333333333}\n",
      "0 0.0 False {'prob': 0.3333333333333333}\n",
      "1 0.0 False {'prob': 0.3333333333333333}\n",
      "1 0.0 False {'prob': 0.3333333333333333}\n",
      "2 0.0 False {'prob': 0.3333333333333333}\n",
      "1 0.0 False {'prob': 0.3333333333333333}\n",
      "0 0.0 False {'prob': 0.3333333333333333}\n",
      "4 0.0 False {'prob': 0.3333333333333333}\n",
      "4 0.0 False {'prob': 0.3333333333333333}\n",
      "0 0.0 False {'prob': 0.3333333333333333}\n",
      "0 0.0 False {'prob': 0.3333333333333333}\n",
      "0 0.0 False {'prob': 0.3333333333333333}\n",
      "0 0.0 False {'prob': 0.3333333333333333}\n",
      "4 0.0 False {'prob': 0.3333333333333333}\n",
      "4 0.0 False {'prob': 0.3333333333333333}\n",
      "4 0.0 False {'prob': 0.3333333333333333}\n",
      "5 0.0 True {'prob': 0.3333333333333333}\n",
      "5 0 True {'prob': 1.0}\n",
      "5 0 True {'prob': 1.0}\n",
      "5 0 True {'prob': 1.0}\n",
      "5 0 True {'prob': 1.0}\n",
      "5 0 True {'prob': 1.0}\n",
      "5 0 True {'prob': 1.0}\n",
      "5 0 True {'prob': 1.0}\n",
      "5 0 True {'prob': 1.0}\n",
      "5 0 True {'prob': 1.0}\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "env = gym.make('FrozenLake-v1')\n",
    "observation = env.reset()\n",
    "for _ in range(30):\n",
    "    env.render()\n",
    "    action = env.action_space.sample()\n",
    "    observation, reward, done, info = env.step(action)\n",
    "    print(observation, reward, done, info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimal Policy, $\\pi$ and Max $Q$\n",
    "$*$  = optimal\n",
    "$$\n",
    "Q(\\text{state}, \\text{action}) \\\\\n",
    "\\\\\n",
    "\\text{Max} Q = \\max_{a'} Q(s, a') \\\\\n",
    "\\pi^*(s) = \\argmax_{a} Q(s, a)\n",
    "$$\n",
    "### rewards\n",
    "\n",
    "$s_0, a_0, r_1, s_1, a_1, r_2, ..., s_{n-1}, a{n-1}, r_n, s_n$\n",
    "\n",
    "$$\\begin{aligned}\n",
    "R &= r_1 + r_2 + ... + r_n \\\\\n",
    "R_t &= r_t + r_{t+1} + ... + r_{n} \\\\\n",
    "R_t &= r_t + R_{t+1} \\\\\n",
    "\\\\\n",
    "R^*_t &= r_t + \\max R_{t+1} \\\\\n",
    "\\\\\n",
    "Q(s, a) &\\approx r + \\max_{a'} Q(s', a') \\\\\n",
    "\\hat{Q}(s,a) &\\leftarrow r + \\max_{a'} \\hat{Q}(s', a')\n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy Q-learning algotrithm\n",
    "- For each $s, a$ initialize table entry $\\hat{Q}(s, a) \\rightarrow 0$\n",
    "- Observe current state $s$\n",
    "- Do forever:\n",
    "    - Select an action $a$ and execute it\n",
    "    - Receive immediate reward $r$\n",
    "    - Observe the new state $s'$\n",
    "    - Update the table entry for $\\hat{Q}(s, a)$ as follows:\n",
    "        - $$\\hat{Q}(s, a) \\rightarrow r + \\max_{a'} \\hat{Q}(s', a')$$\n",
    "    - $s \\rightarrow s'$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success rate: 0.798\n",
      "final Q-table values\n",
      "LEFT\tDOWN\tRIGHT\tUP\n",
      "[[0.531441   0.59049    0.4782969  0.531441  ]\n",
      " [0.531441   0.         0.43046721 0.4782969 ]\n",
      " [0.4782969  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.59049    0.6561     0.         0.531441  ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.6561     0.         0.729      0.59049   ]\n",
      " [0.6561     0.81       0.81       0.        ]\n",
      " [0.729      0.9        0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.81       0.9        0.729     ]\n",
      " [0.81       0.9        1.         0.81      ]\n",
      " [0.         0.         0.         0.        ]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random as pr\n",
    "import gym\n",
    "from gym.envs.registration import register\n",
    "\n",
    "def rargmax(vector):\n",
    "    m = np.amax(vector)\n",
    "    indices = np.nonzero(vector == m)[0]\n",
    "    return pr.choice(indices)\n",
    "\n",
    "register(\n",
    "    id = 'FrozenLake-v3', \n",
    "    entry_point = 'gym.envs.toy_text:FrozenLakeEnv', \n",
    "    kwargs = {'map_name' : '4x4', \n",
    "              'is_slippery' : False}\n",
    ")\n",
    "\n",
    "env = gym.make('FrozenLake-v3')\n",
    "# initialize table with all zeros\n",
    "Q = np.zeros([env.observation_space.n, env.action_space.n])\n",
    "# set learning parameters\n",
    "num_episodes = 2000\n",
    "discount = 0.9\n",
    "\n",
    "# create lists to contain total rewards and steps per episode\n",
    "rList = []\n",
    "for i in range(num_episodes):\n",
    "    # reset environment and get first new observation\n",
    "    state = env.reset()\n",
    "    rAll = 0\n",
    "    done = False\n",
    "    \n",
    "    # decaying var\n",
    "    e = 1. / ((i // 100) + 1)\n",
    "    \n",
    "    # the Q-table learning algorithm\n",
    "    while not done:\n",
    "        # decaying e-greedy\n",
    "        if np.random.rand(1) < e:\n",
    "            action = env.action_space.sample()\n",
    "        else:\n",
    "            action = np.argmax(Q[state, :])\n",
    "        # first run\n",
    "        # action = rargmax(Q[state, :])\n",
    "        \n",
    "        # add random noise\n",
    "        # action = np.argmax(Q[state, :] + np.random.randn(1, env.action_space.n) / (i + 1))\n",
    "        \n",
    "        # get new state and reward from environment\n",
    "        new_state, reward, done, _ = env.step(action)\n",
    "        \n",
    "        # update Q-table with new knowledge using learning rate\n",
    "        Q[state, action] = reward + discount * np.max(Q[new_state, :])\n",
    "        \n",
    "        rAll += reward\n",
    "        state = new_state\n",
    "    rList.append(rAll)\n",
    "# print(Q)\n",
    "\n",
    "print(f'success rate: {str(sum(rList) / num_episodes)}')\n",
    "print('final Q-table values')\n",
    "print('LEFT\\tDOWN\\tRIGHT\\tUP')\n",
    "print(Q)\n",
    "plt.bar(range(len(rList)), rList)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploit vs. Exploration\n",
    "- exploit은 알려진 정보만을 사용, exploration은 다 한번 가본다.\n",
    "\n",
    "### E-greedy\n",
    "- 주사위를 던진다.\n",
    "```\n",
    "e = 0.1\n",
    "if rand < e:\n",
    "    a = random\n",
    "else:\n",
    "    a = argmax(Q(s, a))\n",
    "```\n",
    "### decaying E-greedy\n",
    "- 학습 할 수록 exploit쪽으로 간다.\n",
    "```\n",
    "for i in range(1000):\n",
    "    e = 0.1 / (i + 1)\n",
    "    if rand < e:\n",
    "        a = random\n",
    "    else:\n",
    "        a = argmax(Q(s, a))\n",
    "```\n",
    "\n",
    "### add random noise\n",
    "- Q 테이블에 랜덤값을 더한 다음 exploit 한다.\n",
    "- decaying을 더하면, 학습 할 수록 랜덤 폭을 줄인다.\n",
    "\n",
    "## Learning $Q(s, a)$ with discounted reward\n",
    "- 최단거리를 구하기 위함. 보상을 빨리 받는게 좋다.\n",
    "- 미래의 리워드를 디스카운트 해버린다.\n",
    "    - $\\gamma = 0.9$ 감마를 곱해준다.\n",
    "\n",
    "$$\\begin{aligned}\n",
    "\\hat{Q}(s, a) \\rightarrow r + \\gamma \\times \\max_{a'} \\hat{Q}(s', a') \\\\\n",
    "\n",
    "\\end{aligned}$$\n",
    "\n",
    "$$\\begin{aligned}\n",
    "R &= r_1 + r_2 + ... + r_n \\\\\n",
    "R_t &= r_t + r_{t+1} + ... + r_{n} \\\\\n",
    "\\\\\n",
    "R_t &= r_t + \\gamma r_{t+1} + \\gamma^2 r_{t+2} + ... + \\gamma^{n-t} r_n \\\\\n",
    "&= r_t + \\gamma(r_{t+1} + \\gamma r_{t+2} + ...) \\\\\n",
    "&= r_t + \\gamma R_{t+1} \\\\\n",
    "\\\\\n",
    "R^*_t &= r_t + \\gamma \\max R_{t+1} \\\\\n",
    "\\end{aligned}$$"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5124c4102780756447861f2202c8e6af741ac1f02ea0d1c7b65e3af0ab9746c4"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('venv-mac': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
