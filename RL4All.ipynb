{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모두를 위한 RL 강좌\n",
    "- pygame을 쓴다!?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-25 18:16:09.118 Python[33897:5881234] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to /var/folders/j5/788vvhdj6q377rgwpbpy3k580000gn/T/org.python.python.savedState\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.0 False {'prob': 0.3333333333333333}\n",
      "1 0.0 False {'prob': 0.3333333333333333}\n",
      "1 0.0 False {'prob': 0.3333333333333333}\n",
      "5 0.0 True {'prob': 0.3333333333333333}\n",
      "5 0 True {'prob': 1.0}\n",
      "5 0 True {'prob': 1.0}\n",
      "5 0 True {'prob': 1.0}\n",
      "5 0 True {'prob': 1.0}\n",
      "5 0 True {'prob': 1.0}\n",
      "5 0 True {'prob': 1.0}\n",
      "5 0 True {'prob': 1.0}\n",
      "5 0 True {'prob': 1.0}\n",
      "5 0 True {'prob': 1.0}\n",
      "5 0 True {'prob': 1.0}\n",
      "5 0 True {'prob': 1.0}\n",
      "5 0 True {'prob': 1.0}\n",
      "5 0 True {'prob': 1.0}\n",
      "5 0 True {'prob': 1.0}\n",
      "5 0 True {'prob': 1.0}\n",
      "5 0 True {'prob': 1.0}\n",
      "5 0 True {'prob': 1.0}\n",
      "5 0 True {'prob': 1.0}\n",
      "5 0 True {'prob': 1.0}\n",
      "5 0 True {'prob': 1.0}\n",
      "5 0 True {'prob': 1.0}\n",
      "5 0 True {'prob': 1.0}\n",
      "5 0 True {'prob': 1.0}\n",
      "5 0 True {'prob': 1.0}\n",
      "5 0 True {'prob': 1.0}\n",
      "5 0 True {'prob': 1.0}\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "env = gym.make('FrozenLake-v1')\n",
    "observation = env.reset()\n",
    "for _ in range(30):\n",
    "    env.render()\n",
    "    action = env.action_space.sample()\n",
    "    observation, reward, done, info = env.step(action)\n",
    "    print(observation, reward, done, info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimal Policy, $\\pi$ and Max $Q$\n",
    "$*$  = optimal\n",
    "$$\n",
    "Q(\\text{state}, \\text{action}) \\\\\n",
    "\\\\\n",
    "\\text{Max} Q = \\max_{a'} Q(s, a') \\\\\n",
    "\\pi^*(s) = \\argmax_{a} Q(s, a)\n",
    "$$\n",
    "### rewards\n",
    "\n",
    "$$s_0, a_0, r_1, s_1, a_1, r_2, ..., s_{n-1}, a_{n-1}, r_n, s_n$$\n",
    "\n",
    "$$\\begin{aligned}\n",
    "R &= r_1 + r_2 + ... + r_n \\\\\n",
    "R_t &= r_t + r_{t+1} + ... + r_{n} \\\\\n",
    "R_t &= r_t + R_{t+1} \\\\\n",
    "\\\\\n",
    "R^*_t &= r_t + \\max R_{t+1} \\\\\n",
    "\\\\\n",
    "Q(s, a) &\\approx r + \\max_{a'} Q(s', a') \\\\\n",
    "\\hat{Q}(s,a) &\\leftarrow r + \\max_{a'} \\hat{Q}(s', a')\n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy Q-learning algotrithm\n",
    "- For each $s, a$ initialize table entry $\\hat{Q}(s, a) \\rightarrow 0$\n",
    "- Observe current state $s$\n",
    "- Do forever:\n",
    "    - Select an action $a$ and execute it\n",
    "    - Receive immediate reward $r$\n",
    "    - Observe the new state $s'$\n",
    "    - Update the table entry for $\\hat{Q}(s, a)$ as follows:\n",
    "        - $$\\hat{Q}(s, a) \\leftarrow r + \\max_{a'} \\hat{Q}(s', a')$$\n",
    "    - $s \\leftarrow s'$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success rate: 0.9555\n",
      "final Q-table values\n",
      "LEFT\tDOWN\tRIGHT\tUP\n",
      "[[0.         0.         0.95099005 0.        ]\n",
      " [0.         0.         0.96059601 0.        ]\n",
      " [0.         0.970299   0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.9801     0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.99       0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         0.        ]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random as pr\n",
    "import gym\n",
    "from gym.envs.registration import register\n",
    "\n",
    "def rargmax(vector):\n",
    "    m = np.amax(vector)\n",
    "    indices = np.nonzero(vector == m)[0]\n",
    "    return pr.choice(indices)\n",
    "\n",
    "def frozen_lake_lab(epochs = 2000, \n",
    "                    learning_rate = 0.1, \n",
    "                    decaying_rate = 100, \n",
    "                    discount_rate = 0.99,\n",
    "                    method = 'random_noise', \n",
    "                    size = '4x4', \n",
    "                    is_slippery = False):\n",
    "    if method not in ('random noise', 'decaying e-greedy'):\n",
    "        method = 'e-greedy'\n",
    "    register(\n",
    "        id = 'FrozenLake-v3', \n",
    "        entry_point = 'gym.envs.toy_text:FrozenLakeEnv', \n",
    "        kwargs = {'map_name' : size, \n",
    "                'is_slippery' : is_slippery}\n",
    "    )\n",
    "\n",
    "    env = gym.make('FrozenLake-v3')\n",
    "    # initialize table with all zeros\n",
    "    Q = np.zeros([env.observation_space.n, env.action_space.n])\n",
    "    # set learning parameters\n",
    "    num_episodes = epochs\n",
    "    discount = discount_rate\n",
    "\n",
    "    # create lists to contain total rewards and steps per episode\n",
    "    rList = []\n",
    "    for i in range(num_episodes):\n",
    "        # reset environment and get first new observation\n",
    "        state = env.reset()\n",
    "        rAll = 0\n",
    "        done = False\n",
    "        \n",
    "        # decaying var\n",
    "        e = 1. / ((i // decaying_rate) + 1)\n",
    "        \n",
    "        # the Q-table learning algorithm\n",
    "        while not done:\n",
    "            # decaying e-greedy\n",
    "            if method == 'decaying e-greedy':\n",
    "                if np.random.rand(1) < e:\n",
    "                    action = env.action_space.sample()\n",
    "                else:\n",
    "                    action = np.argmax(Q[state, :])\n",
    "            elif method == 'random noise':\n",
    "                action = np.argmax(Q[state, :] + np.random.randn(1, env.action_space.n) / (i + 1))\n",
    "            else:\n",
    "                action = rargmax(Q[state, :])\n",
    "            \n",
    "            # add random noise\n",
    "            \n",
    "            # get new state and reward from environment\n",
    "            new_state, reward, done, _ = env.step(action)\n",
    "            \n",
    "            # update Q-table with new knowledge using learning rate\n",
    "            Q[state, action] = (1 - learning_rate) * Q[state, action] + learning_rate * (reward + discount * np.max(Q[new_state, :]))\n",
    "            \n",
    "            rAll += reward\n",
    "            state = new_state\n",
    "        rList.append(rAll)\n",
    "    # print(Q)\n",
    "\n",
    "    print(f'success rate: {str(sum(rList) / num_episodes)}')\n",
    "    print('final Q-table values')\n",
    "    print('LEFT\\tDOWN\\tRIGHT\\tUP')\n",
    "    print(Q)\n",
    "    plt.bar(range(len(rList)), rList)\n",
    "    plt.show()\n",
    "\n",
    "frozen_lake_lab()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploit vs. Exploration\n",
    "- exploit은 알려진 정보만을 사용, exploration은 다 한번 가본다.\n",
    "\n",
    "### E-greedy\n",
    "- 주사위를 던진다.\n",
    "```\n",
    "e = 0.1\n",
    "if rand < e:\n",
    "    a = random\n",
    "else:\n",
    "    a = argmax(Q(s, a))\n",
    "```\n",
    "### decaying E-greedy\n",
    "- 학습 할 수록 exploit쪽으로 간다.\n",
    "```\n",
    "for i in range(1000):\n",
    "    e = 0.1 / (i + 1)\n",
    "    if rand < e:\n",
    "        a = random\n",
    "    else:\n",
    "        a = argmax(Q(s, a))\n",
    "```\n",
    "\n",
    "### add random noise\n",
    "- Q 테이블에 랜덤값을 더한 다음 exploit 한다.\n",
    "- decaying을 더하면, 학습 할 수록 랜덤 폭을 줄인다.\n",
    "\n",
    "## Learning $Q(s, a)$ with discounted reward\n",
    "- 최단거리를 구하기 위함. 보상을 빨리 받는게 좋다.\n",
    "- 미래의 리워드를 디스카운트 해버린다.\n",
    "    - $\\gamma = 0.9$ 감마를 곱해준다.\n",
    "\n",
    "$$\\begin{aligned}\n",
    "\\hat{Q}(s, a) \\rightarrow r + \\gamma \\times \\max_{a'} \\hat{Q}(s', a') \\\\\n",
    "\n",
    "\\end{aligned}$$\n",
    "\n",
    "$$\\begin{aligned}\n",
    "R &= r_1 + r_2 + ... + r_n \\\\\n",
    "R_t &= r_t + r_{t+1} + ... + r_{n} \\\\\n",
    "\\\\\n",
    "R_t &= r_t + \\gamma r_{t+1} + \\gamma^2 r_{t+2} + ... + \\gamma^{n-t} r_n \\\\\n",
    "&= r_t + \\gamma(r_{t+1} + \\gamma r_{t+2} + ...) \\\\\n",
    "&= r_t + \\gamma R_{t+1} \\\\\n",
    "\\\\\n",
    "R^*_t &= r_t + \\gamma \\max R_{t+1} \\\\\n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deterministic vs. Stochastic(nondeterministic)\n",
    "- in deterministic models, the output of the model is fully determined by the parameter values and the initial conditions\n",
    "- stochastic models possess some inherent randomness.\n",
    "    - the same set of parameter values and initial conditions will lead to an ensemble of different outputs\n",
    "- Q 학습 당시, input과 output의 관계를 믿을 수 없기 때문.\n",
    "- Q를 따를 때 약간만 따르고, 업데이트할 때도 약간만 한다.\n",
    "\n",
    "### Learning **incrementally**\n",
    "$$\n",
    "\\hat{Q}(s, a) \\leftarrow r + \\gamma \\max_{a'} \\hat{Q}(s', a')\n",
    "$$\n",
    "learning rate, $\\alpha$ 도입.\n",
    "$$\n",
    "\\hat{Q}(s, a) \\leftarrow (1 - \\alpha) \\hat{Q}(s, a) + \\alpha (r + \\gamma \\max_{a'} \\hat{Q}(s', a'))\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mash/Projects/mash-ML/venv-mac/lib/python3.9/site-packages/gym/envs/registration.py:595: UserWarning: \u001b[33mWARN: Overriding environment FrozenLake-v3\u001b[0m\n",
      "  logger.warn(f\"Overriding environment {id}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success rate: 0.719\n",
      "final Q-table values\n",
      "LEFT\tDOWN\tRIGHT\tUP\n",
      "[[4.37487227e-01 4.33264892e-03 9.13184581e-03 2.81201412e-02]\n",
      " [2.29698775e-04 2.19016246e-04 1.69071652e-03 5.47796386e-01]\n",
      " [5.09636771e-03 6.41733141e-03 6.84495593e-03 6.29344169e-01]\n",
      " [2.69865484e-04 2.38769481e-04 1.43509748e-03 4.09395576e-01]\n",
      " [4.85869777e-01 2.27975043e-04 7.87704993e-03 1.46040692e-03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [5.12582207e-01 1.82770711e-07 2.23719688e-04 4.91863298e-07]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [1.79305664e-04 8.53057914e-04 1.33164500e-03 6.98226747e-01]\n",
      " [0.00000000e+00 8.02069680e-01 1.01373489e-03 5.30900802e-04]\n",
      " [9.15017893e-01 0.00000000e+00 1.91487787e-04 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [1.16332830e-03 0.00000000e+00 9.33078254e-01 0.00000000e+00]\n",
      " [0.00000000e+00 9.99089614e-01 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "frozen_lake_lab(method='random noise', \n",
    "                epochs=2000, \n",
    "                learning_rate=0.85,\n",
    "                is_slippery=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Q-function Approximation\n",
    "- 네트웍을 이용. 입력은 $s$만 주고 output layer에서 모든 $a$에 대한 $Q$값을 다 출력한다.\n",
    "\t- 즉, $Q(s, a) \\rightarrow \\text{Q-value}$로 접근하는게 아니라, $Q(s) \\rightarrow [Qv_1, Qv_2, Qv_3, Qv_4]$ 가 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Q-Network training (linear regression)\n",
    "- $s$를 입력했을 때 linear regression에서 forward하면 출력은 $W_s$가 된다. 이 $W_s$가 optimal한 $Q^*$(label)를 만들어 내도록 학습을 해야 함.\n",
    "- $H$(hypothesis)가 있고, 실제 값을 $y$라 하면 비용함수를 최소화하는 문제가 된다.\n",
    "$$\\begin{aligned}\n",
    "H(x) &= W_x \\\\\n",
    "\\text{cost}(W) &= \\frac{1}{m}\\sum_{i=1}^m(W_x^{(i)} - y^{(i)})^2\n",
    "\\end{aligned}$$\n",
    "- MSE를 떠올려보면 아래와 같이 되는데, \n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\text{cost}(W) &= (W_s - y)^2 \\\\\n",
    "y &= r + \\gamma \\max Q(s') \\\\\n",
    "&= Q^*\n",
    "\\end{aligned}\n",
    "$$\n",
    "- $W_s = Q_{\\text{prediction}} = \\hat{Q}$ 이다. (hat은 예측값을 의미)\n",
    "$$\n",
    "\\begin{aligned}\n",
    "W_s = \\hat{Q}(s, a|\\theta)\n",
    "\\end{aligned}\n",
    "$$\n",
    "- $\\theta$는 weight, 즉, 네트워크 자체가 된다. 네트워크를 통과한 a라는 의미."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Q-Network training (math notation)\n",
    "- 위에서, $cost(W)$는 $\\hat{Q}$와 $Q^*$의 차이의 제곱이 된다. 이게 최소가 되어야 하므로, 우리가 바라는 것은 $\\hat{Q}(s, a|\\theta) \\approx Q^*(s, a)$가 된다.\n",
    "\n",
    "$$\\min_{\\theta}\\sum_{t=0}^T[\\hat{Q}(s_t, a_t|\\theta) - (r_t + \\gamma \\max_{a'}\\hat{Q}(s_{t+1}, a'|\\theta))]^2\n",
    "$$\n",
    "- $\\theta$(weight)를 통해 만들어 내는 예측값($\\hat{Q}$)과 $Q^*$의 차의 제곱이 최소화 되는 $\\theta$를 구해라. 이것이 목표!\n",
    "- 전처리($\\phi$) : $\\phi_1 \\leftarrow \\phi(s_1)$, 즉, $s_1$을 전처리하면 $\\phi_1$가 된다.\n",
    "    - 이미지를 처리 가능한 데이터화 하는 등의 작업\n",
    "    - 간단한 상황에서는 $\\phi \\approx s$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### pseudo code @deepmind\n",
    "- Initialize action-value function $Q$ with random weights\n",
    "- for $\\text{episode} = 1, M$ do\n",
    "    - Initialize sequence $s_1 = \\{x_1\\}$ and preprocessed sequenced $\\phi_1 = \\phi(s_1)$\n",
    "    - for $t = 1, T$ do\n",
    "\t    - With probability $\\epsilon$ select a random action $a_t$\n",
    "\t    - otherwise select $a_t = \\max_a Q^* (\\phi(s_t, a|\\theta)$\n",
    "\t    - Execute action $a_t$ in gym and observe reward $r_t$ and image $x_{t+1}$\n",
    "\t    - Set $s_{t+1} = s_t, a_t, x_{t+1}$ and preprocess $\\phi_{t+1} = \\phi(s_{t+1})$\n",
    "\t    - Set $y_j = \\begin{cases}r_j & \\text{for terminal} \\phi_{j+1}\\\\r_j + \\gamma \\max_{a'} Q(\\phi_{j+1}, a'|\\theta) & \\text{for non-terminal} \\phi_{j+1} \\end{cases}$\n",
    "\t    - Perform a gradient descent step on $(y_j - Q(\\phi_j, a_j|\\theta))^2$ according to equation 3\n",
    "\t- end for\n",
    "- end for"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Y label and loss function\n",
    "\n",
    "Set $y_j = \\begin{cases}r_j & \\text{for terminal} \\phi_{j+1}\\\\r_j + \\gamma \\max_{a'} Q(\\phi_{j+1}, a'|\\theta) & \\text{for non-terminal} \\phi_{j+1} \\end{cases}$\n",
    "Perform a **gradient descent** step on ==**loss function**== : $(y_j - Q(\\phi_j, a_j|\\theta))^2$ according to equation 3\n",
    "\n",
    "- terminal : 마지막 상태 (즉, goal에 도착)\n",
    "- $r_j$는 해당 상태에서의 reward. 즉, goal에서만 1점이고 나머지는 모두 0점."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Deterministic or Stochastic?\n",
    "- target으로 lerning rate $\\alpha$가 적용된 값을 주지 않아도 되는지?\n",
    "- 된다. linear regression하면서 어차피 일어나게 되어 있으니."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Convergence\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\min_{\\theta}\\sum_{t=0}^T[\\hat{Q}(s_t, a_t|\\theta) - (r_t + \\gamma \\max_{a'}\\hat{Q}(s_{t+1}, a'|\\theta))]^2\n",
    "\\end{aligned}\n",
    "$$\n",
    "- Converges to $Q^*$ using table lookup representation\n",
    "\t- 테이블의 경우는 converge 한다.\n",
    "- But ==**diverges**== using neural networks due to;\n",
    "\t- Correlations between samples\n",
    "\t- Non-stationary targets\n",
    "- 뉴럴넷에서는 converge가 안되므로 학습이 안되는데... 딥마인드에서 해법을 내놓았다. ==**DQN\n",
    "- DQN: Deep, Replay, Separated networks "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실습\n",
    "- One-hot 인코딩\n",
    "    - state를 전달할 때, 전체 state 사이즈의 배열을 만들고 전달하려는 state만 1을 켜서 만드는 기법."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success rate : 54.50000000000001%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x13d467040>]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# One-hot encoding\n",
    "import numpy as np\n",
    "\n",
    "def one_hot(x, size=16):\n",
    "    return np.identity(size)[x:x + 1]\n",
    "\n",
    "\n",
    "# import tensorflow.compat.v1 as tf\n",
    "from tensorflow import compat\n",
    "# 버전 차이때문에 v1의 것을 끌어다 사용\n",
    "tf = compat.v1\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "env = gym.make('FrozenLake-v1')\n",
    "input_size = env.observation_space.n\n",
    "output_size = env.action_space.n\n",
    "learning_rate = 0.1\n",
    "\n",
    "# establish the feed-forward part of the network used to choose actions\n",
    "X = tf.placeholder(shape = [1, input_size], dtype = tf.float32) # state input\n",
    "W = tf.Variable(tf.random.uniform([input_size, output_size], 0, 0.01))  # weight\n",
    "\n",
    "Q_hat = tf.matmul(X, W) # out Q prediction\n",
    "Y = tf.placeholder(shape = [1, output_size], dtype = tf.float32)   # Y label\n",
    "\n",
    "loss = tf.reduce_sum(tf.square(Y - Q_hat))\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "\n",
    "# set Q-learning related parameters\n",
    "discount = .99\n",
    "num_episodes = 3000\n",
    "\n",
    "# create lists to contain total rewards and steps per episode\n",
    "rList = []\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(num_episodes):\n",
    "        # reset env and get first new observation\n",
    "        s = env.reset()\n",
    "        e = 1. / ((i // 50) + 10)\n",
    "        rAll = 0\n",
    "        done = False\n",
    "        local_loss = []\n",
    "        \n",
    "        # Q-Network training !\n",
    "        while not done:\n",
    "            # choose an action by greedily (with e chance of random action) from q-network\n",
    "            Qs = sess.run(Q_hat, feed_dict = {X: one_hot(s)})\n",
    "            if np.random.rand(1) < e:\n",
    "                a = env.action_space.sample()\n",
    "            else:\n",
    "                a = np.argmax(Qs)\n",
    "            \n",
    "            # get new state and reward from environment\n",
    "            s1, reward, done, info = env.step(a)\n",
    "            \n",
    "            if done:\n",
    "                # update Q, and no Q_s1, because it's terminal state\n",
    "                Qs[0, a] = reward\n",
    "                # (1, 16) X (16, 4) matmul 한 결과이므로 (1, 4)의 shape을 가지게 되고, [0, a]로 접근 가능\n",
    "            else:\n",
    "                # obtain the Q_s1 values by feeding the new state through our network\n",
    "                Qs1 = sess.run(Q_hat, feed_dict = {X: one_hot(s1)})\n",
    "                # update Qs\n",
    "                Qs[0, a] = reward + discount * np.max(Qs1)\n",
    "            \n",
    "            # train our network using target (Y) and predicted Q (q_hat) values\n",
    "            sess.run(train, feed_dict = {X: one_hot(s), Y: Qs})\n",
    "            \n",
    "            rAll += reward\n",
    "            s = s1\n",
    "        rList.append(rAll)\n",
    "    \n",
    "print(f'success rate : {str(sum(rList) / num_episodes * 100)}%')\n",
    "plt.plot(rList)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5124c4102780756447861f2202c8e6af741ac1f02ea0d1c7b65e3af0ab9746c4"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('venv-mac': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
